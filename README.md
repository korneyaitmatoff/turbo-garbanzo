## Лабораторная работа 1

**Задачи**:
- Установить средство контейнеризации docker.
- Изучить применение и принципы docker.
- Изучить утилиту docker-compose и структуру файла docker-compose.yml.
- Развернуть любую БД при помощи docker-compose.

Развернута база данных postgresql.
В image указан образ реализации базы данных.
restart: always означает, что в случае отказа базы данных контейнер с ней будет перезапущен.
В environment указаны параметры по умолчанию: пользователь, пароль, имя базы данных.
В volumes указан том, который хранит данные из БД.
В ports указаны порты для подключения: первый порт указывает порт хост системы: а второй порт БД внутри контейнера.

## Лабораторная 2

**Задачи**
- Согласно вашему варианту разработать приложение, реализующее CRUD на данные, хранящиеся в БД развернутой в ЛР 1.
- Изучить файлы сборки образов docker и разработать их для созданных приложений.
- Собрать файл docker-compose.yml для запуска приложений.

Сделано CRUD, которое работает с pgsql. Реализовано на python3.12 и библиотеки fastapi. Подключен swagger (перейти по пути /docs (localhost:8081/docs))


## Лабораторная 3

**Задачи**
- Согласно вашему варианту разработать приложение для формирования отчета на данных, хранящиеся в БД развернутой в ЛР 1.

Реализован сервис отчетов в отдельном образые и контейнере.
Добавлен в initdb.sql скрипт для генерации данных.

## Лабораторная 4
**Задачи**
-Убрать прямой доступ к сервису отчетов. 
- Реализовать возможность получения отчета через темплейт из первого сервиса.

Ограничил доступ к контейнеру отчетов с хост машины.
Добавил ендпоинт для получения отчета через API CRUD.


## Лабораторная 5

**Задачи**
- Поднять любое объектное файловое хранилище, например MinIO (https://min.io/docs/minio/container/index.html )
- Изменить логику построения отчета и его взаимодействия с основным сервисом так, что отчет будет сохраняться в файловое хранилище, а основной сервис будет скачивать его оттуда

Поднял s3 minio.
Сервис reports записывает туда файл
Cервис CRUD читает оттуда файл  


## Лабораторная 6
**Задачи**
- Установить брокер сообщений RabbitMQ.
- Изменить логику построения отчета и его взаимодействия с основным сервисом так, что данные для формирования отчета пересылались через очередь. Ответ о построении отчета также должен пересылаться через очередь, а в основном сервисе должно быть реализовано асинхронное ожидание этого события.

Поднял rabbitmq.
Сервис отчетов теперь постоянно слушает сообщения и отдает при формировании отчета.
Основной сервис отправляет сообщения в брокер и ожидает сообщения с именем файла в s3.



## Лабораторная 7
**Задачи**
- Разработать клиентский бенчмарка для нагрузочного параллельного тестирования разработанной системы.
- Построить отчет показывающий зависимость скорости ответа и пропускной способности системы, от количества параллельных клиентов.

Поставил locust.
Довел сервис до отказа, тестировал на 2000+ RPS

![Снимок экрана 2025-04-17 в 22 00 22](https://github.com/user-attachments/assets/4d5b7f25-e792-4331-a5a6-c1260c5e65e3)
![Снимок экрана 2025-04-17 в 22 01 00](https://github.com/user-attachments/assets/a2b3ec25-ea81-42fd-bc4d-941344835176)
